<!DOCTYPE html>
<html>
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
      Coursera 机器学习课程总结1 - 线性回归和逻辑回归 | Hanying Garden 
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
      <meta name="author" content="Zhang Hanying">
    
    

    <meta name="description" content="机器学习课程的总结 - 线性回归和逻辑回归">
<meta name="keywords" content="ML">
<meta property="og:type" content="article">
<meta property="og:title" content="Coursera 机器学习课程总结1 - 线性回归和逻辑回归 | Hanying Garden">
<meta property="og:url" content="http://hanyinggarden.net/2017/08/02/ML-review-1/index.html">
<meta property="og:site_name" content="Hanying Garden">
<meta property="og:description" content="机器学习课程的总结 - 线性回归和逻辑回归">
<meta property="og:image" content="http://hanyinggarden.net/2017/08/02/ML-review-1/sigmoid.jpg">
<meta property="og:image" content="http://hanyinggarden.net/2017/08/02/ML-review-1/logistic_loss_func_total.png">
<meta property="og:image" content="http://hanyinggarden.net/2017/08/02/ML-review-1/logistic_loss_func.jpg">
<meta property="og:updated_time" content="2017-08-03T02:08:33.958Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Coursera 机器学习课程总结1 - 线性回归和逻辑回归 | Hanying Garden">
<meta name="twitter:description" content="机器学习课程的总结 - 线性回归和逻辑回归">
<meta name="twitter:image" content="http://hanyinggarden.net/2017/08/02/ML-review-1/sigmoid.jpg">
    
    
    
      <link rel="icon" type="image/x-icon" href="/favicon.png">
    
    <link rel="stylesheet" href="/css/uno.css">
    <link rel="stylesheet" href="/css/highlight.css">
    <link rel="stylesheet" href="/css/archive.css">
    <link rel="stylesheet" href="/css/china-social-icon.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>
<body>

    <!-- hexo-inject:begin --><!-- hexo-inject:end --><span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
    </span>

    

<header class="panel-cover panel-cover--collapsed">


  <div class="panel-main">

  
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">Hanying Garden</a></h1>
        <hr class="panel-cover__divider" />

        
        <p class="panel-cover__description">
          自律 面对
        </p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />
        

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">首页</a></li>
              
                
                <li class="navigation__item"><a href="/about" title="" class="">关于</a></li>
              

            </ul>
          </nav>

          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

-------------------------------->

<!-- add social info here -->



<nav class="cover-navigation navigation--social">
  <ul class="navigation">

    
      <!-- Github -->
      <li class="navigation__item">
        <a href="https://github.com/runnphoenix" title="My GitHub Page">
          <i class='icon icon-social-github'></i>
          <span class="label">GitHub</span>
        </a>
      </li>
    

    <!-- China social icon -->
    <!--
    
      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-douban'></i>
          <span class="label">Douban</span>
        </a>
      </li>

      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-weibo'></i>
          <span class="label">Weibo</span>
        </a>
      </li>

    -->



  </ul>
</nav>




        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            

<article class="post-container post-container--single">

  <header class="post-header">
    
    <h1 class="post-title">Coursera 机器学习课程总结1 - 线性回归和逻辑回归</h1>

    

    <div class="post-meta">
      <time datetime="2017-08-02" class="post-meta__date date">2017-08-02</time> 

      <span class="post-meta__tags tags">

          
            <font class="categories">
            &#8226; 分类:
            <a class="categories-link" href="/categories/ML/">ML</a>
            </font>
          

          
             &#8226; 标签:
            <font class="tags">
              <a class="tags-link" href="/tags/ML/">ML</a>
            </font>
          

      </span>
    </div>
    
    

  </header>

  <section id="post-content" class="article-content post">
    <a id="more"></a>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<h3 id="监督学习-VS-非监督学习"><a href="#监督学习-VS-非监督学习" class="headerlink" title="监督学习 VS. 非监督学习"></a>监督学习 VS. 非监督学习</h3><p>监督学习和非监督学习的区分原则很直观: 给定训练数据的同时，是否也给了每个数据的”正确结果”。举例来说，对于一个图像分类问题，在给定图像的同时，还会给出图像属于哪个分类的说明，这就属于监督学习；而对于聚类算法来说，只是给出一堆数据，要求把数据按照相似性分成几个部分，这就是非监督学习。</p>
<p><code>强化学习</code>通常被看成是与监督学习和非监督学习并列的一种学习方式。</p>
<h3 id="理论重点"><a href="#理论重点" class="headerlink" title="理论重点"></a>理论重点</h3><h4 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h4><p>线性回归部分，介绍了<code>损失函数</code>、<code>梯度递减</code>的概念，是整个机器学习中最重要的基础。</p>
<p>损失函数又叫目标函数，可以看作我们的模型预测值与实际值之间差距的大小，损失函数值越小，说明我们的模型越正确。所以，解决一个机器学习问题的总体思路就是:先得到损失函数，然后调整参数，以使目标函数值达到最小。</p>
<p>线性回归的损失函数是<br>$$J(\theta) = \frac{1}{2m}\sum<em>{i=1}^m(h</em>\theta(x^{(i)})-y^{(i)})^2$$</p>
<p>其中，h(x)是我们的假设函数模型<br>$$h_\theta(x) = \theta_0 + \theta_1x_1 + \theta_2x_2 + \cdots + \theta_nx_n$$</p>
<p>梯度递减就是寻找损失函数最小值的一种方法。其过程类似于我们从山上一步一步走到山谷。数学上来说，就是各个方向的偏导数同步减小的过程。其中，步长和步数是可以调整的参数。步长大小要合适，长度太长的话，会容易”跑到对面山上去”，整个地图乱跑；太小的话，在一定的步数之內，可能尚未到达最小点。到达最小点之后，将会在附近徘徊。</p>
<p>偏导很容易计算:<br>$$ \frac{\partial{J(\theta)}}{\partial{\theta<em>0}} = \frac{1}{m}\sum</em>{i=1}^m(h_\theta)(x^{(i)}-y^{(i)})$$</p>
<p>$$ \frac{\partial{J(\theta)}}{\partial{\theta<em>j}} = \frac{1}{m}\sum</em>{i=1}^m(h_\theta)(x^{(i)}-y^{(i)})x_j^{(i)}$$</p>
<p>因此<br>$$\theta_0 = \theta<em>0 - \alpha\frac{1}{m}\sum</em>{i=1}^m(h_\theta)(x^{(i)}-y^{(i)})$$</p>
<p>$$\theta_j = \theta<em>j - \alpha\frac{1}{m}\sum</em>{i=1}^m(h_\theta)(x^{(i)}-y^{(i)})x_j^{(i)}$$</p>
<p>这种递减方式叫做<code>批量梯度递减</code>，因為每次递减都需要所有的训练数据参与，当数据量很大的时候，速度会比較慢。</p>
<p>另外，最后到达的，不一定是最小值，可能只是极小值。</p>
<p>$\theta$ 要统一賦值，如果有三个参数要更新，必須要等到三个参数的新值都计算好以后，再一起賦值。</p>
<p><code>归一化</code>：如果两种特征的值域相差很大，需要将其统一到［-1,1]的范围內。<strong>要注意归一化和正则化的区别。</strong></p>
<h4 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h4><p>逻辑回归本貭上是个分类问題，引入了<code>sigmoid函數</code>：<br><img src="./sigmoid.jpg" alt="sigmoid"></p>
<p>$$ g(z) = \frac{1}{1+e^{-z}} $$</p>
<p>整合输入之后模型变成：</p>
<p>$$ h_\theta(x) = \frac{1}{1+e^{-\theta^Tx}} $$</p>
<p>线性回归的损失函数是<strong>累计误差平方然后求平均</strong>，逻辑回归不一样，逻辑回归是靠<strong>log函数</strong>实现的。</p>
<p><img src="./logistic_loss_func_total.png" alt="cost function"></p>
<p><img src="./logistic_loss_func.jpg" alt="logistic"></p>
<p>sigmoid函数将模型的值域固定在0到1之间，在损失函数中，该值域变成了作用域。从上图可以看出，若y=1，$h_θ(x)$接近1时，损失函数几乎为0，反之，当其接近0时，惩罚将会非常快速地增长。y=0时也是一样的道理。</p>
<h3 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h3><p>第二周逻辑回归的作业，要求我们完成逻辑回归的代码（octave\matlab）并将其应用在两个不同的数据上。</p>
<p>作业第一部分logistic regression，主流程代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div></pre></td><td class="code"><pre><div class="line">%% Machine Learning Online Class - Exercise 2: Logistic Regression</div><div class="line">%</div><div class="line">%  Instructions</div><div class="line">%  ------------</div><div class="line">% </div><div class="line">%  This file contains code that helps you get started on the logistic</div><div class="line">%  regression exercise. You will need to complete the following functions </div><div class="line">%  in this exericse:</div><div class="line">%</div><div class="line">%     sigmoid.m</div><div class="line">%     costFunction.m</div><div class="line">%     predict.m</div><div class="line">%     costFunctionReg.m</div><div class="line">%</div><div class="line">%  For this exercise, you will not need to change any code in this file,</div><div class="line">%  or any other files other than those mentioned above.</div><div class="line">%</div><div class="line"></div><div class="line">%% Initialization</div><div class="line">clear ; close all; clc</div><div class="line"></div><div class="line">%% Load Data</div><div class="line">%  The first two columns contains the exam scores and the third column</div><div class="line">%  contains the label.</div><div class="line"></div><div class="line">data = load(&apos;ex2data1.txt&apos;);</div><div class="line">X = data(:, [1, 2]); y = data(:, 3);</div><div class="line"></div><div class="line">%% ==================== Part 1: Plotting ====================</div><div class="line">%  We start the exercise by first plotting the data to understand the </div><div class="line">%  the problem we are working with.</div><div class="line"></div><div class="line">fprintf([&apos;Plotting data with + indicating (y = 1) examples and o &apos; ...</div><div class="line">         &apos;indicating (y = 0) examples.\n&apos;]);</div><div class="line"></div><div class="line">plotData(X, y);</div><div class="line"></div><div class="line">% Put some labels </div><div class="line">hold on;</div><div class="line">% Labels and Legend</div><div class="line">xlabel(&apos;Exam 1 score&apos;)</div><div class="line">ylabel(&apos;Exam 2 score&apos;)</div><div class="line"></div><div class="line">% Specified in plot order</div><div class="line">legend(&apos;Admitted&apos;, &apos;Not admitted&apos;)</div><div class="line">hold off;</div><div class="line"></div><div class="line">fprintf(&apos;\nProgram paused. Press enter to continue.\n&apos;);</div><div class="line">pause;</div><div class="line"></div><div class="line"></div><div class="line">%% ============ Part 2: Compute Cost and Gradient ============</div><div class="line">%  In this part of the exercise, you will implement the cost and gradient</div><div class="line">%  for logistic regression. You neeed to complete the code in </div><div class="line">%  costFunction.m</div><div class="line"></div><div class="line">%  Setup the data matrix appropriately, and add ones for the intercept term</div><div class="line">[m, n] = size(X);</div><div class="line"></div><div class="line">% Add intercept term to x and X_test</div><div class="line">X = [ones(m, 1) X];</div><div class="line"></div><div class="line">% Initialize fitting parameters</div><div class="line">initial_theta = zeros(n + 1, 1);</div><div class="line"></div><div class="line">% Compute and display initial cost and gradient</div><div class="line">[cost, grad] = costFunction(initial_theta, X, y);</div><div class="line"></div><div class="line">fprintf(&apos;Cost at initial theta (zeros): %f\n&apos;, cost);</div><div class="line">fprintf(&apos;Gradient at initial theta (zeros): \n&apos;);</div><div class="line">fprintf(&apos; %f \n&apos;, grad);</div><div class="line"></div><div class="line">fprintf(&apos;\nProgram paused. Press enter to continue.\n&apos;);</div><div class="line">pause;</div><div class="line"></div><div class="line"></div><div class="line">%% ============= Part 3: Optimizing using fminunc  =============</div><div class="line">%  In this exercise, you will use a built-in function (fminunc) to find the</div><div class="line">%  optimal parameters theta.</div><div class="line"></div><div class="line">%  Set options for fminunc</div><div class="line">options = optimset(&apos;GradObj&apos;, &apos;on&apos;, &apos;MaxIter&apos;, 400);</div><div class="line"></div><div class="line">%  Run fminunc to obtain the optimal theta</div><div class="line">%  This function will return theta and the cost </div><div class="line">[theta, cost] = ...</div><div class="line">	fminunc(@(t)(costFunction(t, X, y)), initial_theta, options);</div><div class="line"></div><div class="line">% Print theta to screen</div><div class="line">fprintf(&apos;Cost at theta found by fminunc: %f\n&apos;, cost);</div><div class="line">fprintf(&apos;theta: \n&apos;);</div><div class="line">fprintf(&apos; %f \n&apos;, theta);</div><div class="line"></div><div class="line">% Plot Boundary</div><div class="line">plotDecisionBoundary(theta, X, y);</div><div class="line"></div><div class="line">% Put some labels </div><div class="line">hold on;</div><div class="line">% Labels and Legend</div><div class="line">xlabel(&apos;Exam 1 score&apos;)</div><div class="line">ylabel(&apos;Exam 2 score&apos;)</div><div class="line"></div><div class="line">% Specified in plot order</div><div class="line">legend(&apos;Admitted&apos;, &apos;Not admitted&apos;)</div><div class="line">hold off;</div><div class="line"></div><div class="line">fprintf(&apos;\nProgram paused. Press enter to continue.\n&apos;);</div><div class="line">pause;</div><div class="line"></div><div class="line">%% ============== Part 4: Predict and Accuracies ==============</div><div class="line">%  After learning the parameters, you&apos;ll like to use it to predict the outcomes</div><div class="line">%  on unseen data. In this part, you will use the logistic regression model</div><div class="line">%  to predict the probability that a student with score 45 on exam 1 and </div><div class="line">%  score 85 on exam 2 will be admitted.</div><div class="line">%</div><div class="line">%  Furthermore, you will compute the training and test set accuracies of </div><div class="line">%  our model.</div><div class="line">%</div><div class="line">%  Your task is to complete the code in predict.m</div><div class="line"></div><div class="line">%  Predict probability for a student with score 45 on exam 1 </div><div class="line">%  and score 85 on exam 2 </div><div class="line"></div><div class="line">prob = sigmoid([1 45 85] * theta);</div><div class="line">fprintf([&apos;For a student with scores 45 and 85, we predict an admission &apos; ...</div><div class="line">         &apos;probability of %f\n\n&apos;], prob);</div><div class="line"></div><div class="line">% Compute accuracy on our training set</div><div class="line">p = predict(theta, X);</div><div class="line"></div><div class="line">fprintf(&apos;Train Accuracy: %f\n&apos;, mean(double(p == y)) * 100);</div><div class="line"></div><div class="line">fprintf(&apos;\nProgram paused. Press enter to continue.\n&apos;);</div><div class="line">pause;</div></pre></td></tr></table></figure></p>
<ul>
<li>1.0 plot数据之前，需要先读入数据，数据格式如下:<br>0.051267,0.69956,1<br>-0.092742,0.68494,1<br>-0.21371,0.69225,1<br>-0.375,0.50219,1<br>-0.51325,0.46564,1<br>-0.52477,0.2098,1<br>-0.39804,0.034357,1<br>-0.30588,-0.19225,1<br>……</li>
</ul>
<p>代码使用load函数把数据读入到data，然后把前两列赋给X，最后一列赋给y。</p>
<ul>
<li>1.1 Visualize Data</li>
</ul>
<p>使用find函数分别将y=0和y=1的数据index赋值给pos和neg，然后分别将index在pos和neg中的X使用不同的标记和颜色plot出来</p>
<ul>
<li>1.2 Implementation<ul>
<li>1.2.1 Sigmoid Function<br>实现Sigmoid函数，没什么难度</li>
<li>1.2.2 Cost Function &amp;&amp; Gradient<br>实现损失函数和梯度，按照公式来即可</li>
<li>1.2.3 Learning parameters using fminunc<br>训练，并把decision boundary画了出来</li>
<li>1.2.4 Evaluating Logistic Regression<br>评估我们的模型准确性</li>
</ul>
</li>
</ul>

  </section>

  

<section class="post-comments">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
      var disqus_shortname = 'hanyinggarden'; 
      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function() {
          var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
          dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>


  
  
  <span id="busuanzi_container_page_pv">本文阅读量: <span id="busuanzi_value_page_pv"></span></span>

</article>


            <footer class="footer">

    <span class="footer__copyright">&copy; 2017. Zhang Hanying. | 由<a href="https://hexo.io/">Hexo</a>强力驱动 | 主题<a href="https://github.com/someus/huno">Huno</a></span>
 
    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container_site_uv">访客数: <span id="busuanzi_value_site_uv">    </span></span>   
    <span id="busuanzi_container_site_pv">总访问量: <span id="busuanzi_value_site_pv"></span></span>
</footer>

        </div>
    </div>

    <!-- js files -->
    <script src="/js/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <script src="/js/scale.fix.js"></script>
    

    

    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript"> 
        $(document).ready(function(){
            MathJax.Hub.Config({ 
                tex2jax: {inlineMath: [['[latex]','[/latex]'], ['\\(','\\)']]} 
            });
        });
    </script>


    

    <script src="/js/awesome-toc.min.js"></script>
    <script>
        $(document).ready(function(){
            $.awesome_toc({
                overlay: true,
                contentId: "post-content",
            });
        });
    </script>


    
    
    <!--kill ie6 -->
<!--[if IE 6]>
  <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
<![endif]--><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

</body>
</html>
